# ğŸš€ High-Performance Production Scraper System

Bu sistem, **binlerce Ã¼rÃ¼nÃ¼ hÄ±zlÄ± ve gÃ¼venli** ÅŸekilde Ã§ekebilecek profesyonel yapÄ±da geliÅŸtirilmiÅŸtir.

## ğŸ¯ Production Features

### âš¡ **Performance Modes**

#### 1. ğŸŒ Conservative Mode (Ultra-Safe)
- **3 concurrent requests**
- **2 second delays**
- **10 retries**
- **Ultra-low API impact**
- **Perfect for sensitive APIs**

#### 2. âš¡ Production Mode (Balanced)
- **8 concurrent requests**
- **500ms delays**
- **5 retries**
- **Production optimized**
- **Recommended for most use cases**

#### 3. ğŸ”¥ Aggressive Mode (Fast)
- **20 concurrent requests**
- **200ms delays**
- **3 retries**
- **Maximum speed**
- **Use with caution**

#### 4. âš™ï¸ Custom Mode
- **User-defined settings**
- **Flexible configuration**
- **Expert users**

### ğŸ—ï¸ **Architecture Features**

#### ğŸ”„ **High-Performance Queue System**
```typescript
- Intelligent job prioritization
- Brand-based load balancing
- Automatic retry with exponential backoff
- Memory management and garbage collection
- Real-time progress tracking
- Checkpoint system for crash recovery
```

#### ğŸ’¾ **Dual Persistence**
```typescript
- Database: Automatic Prisma ORM integration
- Files: Timestamped JSON batch files
- Checkpoints: Resume from interruptions
- Statistics: Comprehensive performance metrics
```

#### ğŸ›¡ï¸ **Error Handling & Recovery**
```typescript
- Graceful error handling
- Automatic retry logic
- Cooldown periods for API protection
- Failed job tracking
- Recovery checkpoints
```

## ğŸš€ Quick Start

### 1. **Start Production Scraper**
```bash
npm run scrape:production
```

### 2. **Choose Performance Mode**
```
ğŸ“Š Performance Modes:
1. ğŸŒ Conservative: 3 concurrent, 2s delay, ultra-safe
2. âš¡ Production: 8 concurrent, 500ms delay, balanced
3. ğŸ”¥ Aggressive: 20 concurrent, 200ms delay, fast
4. âš™ï¸  Custom: Manual configuration
```

### 3. **Select Products**
```
ğŸ¯ Product Selection:
1. ğŸ“¦ All sample products (24 products)
2. ğŸ§ª Small test (6 products)
3. ğŸ¯ Custom amount
4. ğŸ” Brand specific
```

### 4. **Monitor Progress**
```
ğŸ“Š Progress: 150/1000 (15.0%)
âš¡ Rate: 12.5 products/min
â±ï¸  ETA: 68 seconds
ğŸ”„ In Progress: 8
âŒ Failed: 2
```

## ğŸ“Š Performance Estimates

### **Conservative Mode**
- **Rate**: ~5 products/minute
- **1,000 products**: ~3.3 hours
- **10,000 products**: ~33 hours
- **Best for**: Sensitive APIs, overnight runs

### **Production Mode**
- **Rate**: ~12 products/minute  
- **1,000 products**: ~1.4 hours
- **10,000 products**: ~14 hours
- **Best for**: Most production scenarios

### **Aggressive Mode**
- **Rate**: ~25 products/minute
- **1,000 products**: ~40 minutes
- **10,000 products**: ~6.7 hours
- **Best for**: Development, testing, fast runs

## ğŸ› ï¸ Advanced Configuration

### **Environment Variables**
```bash
export SCRAPER_MODE=production          # performance mode
export MAX_MEMORY_MB=1000               # memory limit
export CHECKPOINT_INTERVAL=300000       # checkpoint every 5 min
export LOG_LEVEL=info                   # logging level
```

### **Custom Performance Config**
```typescript
const customConfig = {
  maxConcurrentRequests: 15,
  requestDelay: 300,
  maxRetries: 7,
  batchSize: 75,
  memoryThreshold: 800,
  responseTimeoutMs: 20000
}
```

## ğŸ“ˆ Monitoring & Analytics

### **Real-time Metrics**
```
ğŸ“Š System Stats:
   Memory: 245.7MB used
   Uptime: 15 minutes  
   CPU Load: 450ms
   
ğŸ”¥ Queue Status:
   âœ… Completed: 450
   ğŸ”„ In Progress: 8
   âŒ Failed: 12
   ğŸ“¦ Remaining: 530
```

### **Performance Analytics**
```
ğŸ’¡ Performance Insights:
âœ… Excellent performance! Consider scaling up.
âš¡ Average Rate: 18.5 products/minute
ğŸ¯ Success Rate: 96.2%
ğŸ§  Memory Efficiency: Optimal
```

## ğŸ”§ Troubleshooting

### **Common Issues**

#### 1. **Low Performance**
```bash
# Solutions:
- Increase concurrent requests
- Reduce request delays  
- Check network connectivity
- Monitor API rate limits
```

#### 2. **High Memory Usage**
```bash
# Solutions:
- Reduce batch size
- Lower memory threshold
- Enable garbage collection
- Process smaller chunks
```

#### 3. **API Errors**
```bash
# Solutions:
- Switch to Conservative mode
- Increase retry delays
- Check API status
- Verify authentication
```

### **Recovery from Crashes**
```typescript
// Automatic checkpoint recovery
const checkpoint = productionScraper.getCheckpoint()
if (checkpoint) {
  console.log('ğŸ”„ Resuming from checkpoint...')
  scraper.resumeFromCheckpoint(checkpoint)
}
```

## ğŸ¯ Production Scenarios

### **Scenario 1: Daily Product Sync (1,000 products)**
```bash
Mode: Production
Estimated Time: 1.4 hours
Best Schedule: Night runs (2-4 AM)
Configuration: Default production settings
```

### **Scenario 2: Full Catalog Scraping (50,000 products)**
```bash
Mode: Conservative  
Estimated Time: 7-10 days
Best Approach: Split into chunks
Configuration: Ultra-safe settings
```

### **Scenario 3: Quick Price Updates (500 products)**
```bash
Mode: Aggressive
Estimated Time: 20 minutes
Best Use: Real-time price monitoring
Configuration: Fast, minimal retries
```

## ğŸ”— Integration Examples

### **Cron Job Integration**
```bash
# Daily at 2 AM
0 2 * * * cd /path/to/scraper && npm run scrape:production
```

### **Docker Integration**
```dockerfile
FROM node:18-alpine
COPY . /app
WORKDIR /app
RUN npm install
CMD ["npm", "run", "scrape:production"]
```

### **API Integration**
```typescript
import { ProductionScraper } from './services'

const scraper = new ProductionScraper()
const results = await scraper.scrapeProducts({
  productIds: { zara: zaraIds, pullandbear: pbIds },
  config: PRODUCTION_CONFIG,
  saveToDatabase: true,
  enableMonitoring: true
})
```

## ğŸš€ Scaling Recommendations

### **For 1,000-10,000 products:**
- Use **Production mode**
- Single instance
- Database persistence
- Scheduled runs

### **For 10,000-100,000 products:**
- Use **Conservative mode**
- Multiple instances
- Chunk processing
- Distributed workload

### **For 100,000+ products:**
- Use **Custom configuration**
- Cluster deployment
- Queue systems (Redis)
- Load balancing

---

**ğŸ‰ Ready for production-scale scraping with intelligent performance management!**
